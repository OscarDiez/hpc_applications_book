{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyMmKUTqKkUPOlNhOkrDfD9l"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# Introduction to GPU Computing\n","\n","In today's computational landscape, GPUs (Graphics Processing Units) have evolved beyond their original purpose of rendering graphics. They have become essential tools for high-performance computing (HPC), capable of performing a vast number of calculations simultaneously. This ability to handle massive parallelism makes GPUs particularly useful for scientific simulations, machine learning, and other computationally intensive tasks.\n","\n","In this section, we'll explore the basics of GPU computing, including the architecture of GPUs and the programming models that allow us to harness their power. Specifically, we'll focus on two main approaches: CUDA and OpenACC.\n","\n","## What is GPU Computing?\n","\n","GPU computing involves using a GPU to perform computations that would otherwise be handled by a CPU. Unlike CPUs, which have a few cores optimized for sequential processing, GPUs have thousands of smaller, more efficient cores designed for parallel tasks. This makes GPUs ideal for workloads that can be broken down into many smaller, independent tasks.\n","\n","## Why Use GPUs in HPC?\n","\n","- **Massive Parallelism**: GPUs can execute thousands of threads simultaneously, making them well-suited for parallel algorithms.\n","- **High Throughput**: With their large number of cores, GPUs can process a significant amount of data in parallel, leading to faster execution times for many applications.\n","- **Energy Efficiency**: GPUs can often perform more computations per watt compared to CPUs, making them a more energy-efficient choice for large-scale computations.\n","\n","In the following sections, we will dive into the basics of CUDA and OpenACC, two popular programming models for GPU computing.\n"],"metadata":{"id":"MmDYSoc-vd_0"}},{"cell_type":"markdown","source":["## CUDA Basics\n","\n","CUDA (Compute Unified Device Architecture) is a parallel computing platform and application programming interface (API) model created by NVIDIA. It allows developers to use NVIDIA GPUs for general-purpose processing (an approach known as GPGPU, General-Purpose computing on Graphics Processing Units).\n","\n","### Key Concepts in CUDA\n","\n","- **Thread**: The smallest unit of processing. Each thread runs a copy of the kernel (a function that runs on the GPU).\n","- **Block**: A group of threads that can cooperate amongst themselves via shared memory. Blocks are organized into a grid.\n","- **Grid**: A collection of blocks. The grid represents the entire execution space for a given kernel.\n","\n","Let's start by writing a simple CUDA program to perform matrix multiplication, a common operation in many scientific and engineering applications.\n"],"metadata":{"id":"w8O4UnqjviCi"}},{"cell_type":"markdown","source":["## CUDA Basics\n","\n","CUDA (Compute Unified Device Architecture) is a parallel computing platform and application programming interface (API) model created by NVIDIA. It allows developers to use NVIDIA GPUs for general-purpose processing (an approach known as GPGPU, General-Purpose computing on Graphics Processing Units).\n","\n","### Key Concepts in CUDA\n","\n","- **Thread**: The smallest unit of processing. Each thread runs a copy of the kernel (a function that runs on the GPU).\n","- **Block**: A group of threads that can cooperate amongst themselves via shared memory. Blocks are organized into a grid.\n","- **Grid**: A collection of blocks. The grid represents the entire execution space for a given kernel.\n","\n","Let's start by writing a simple CUDA program to perform matrix multiplication, a common operation in many scientific and engineering applications.\n"],"metadata":{"id":"jNsCEt9Qvk7T"}},{"cell_type":"code","source":["# Check the GPU available in Google Colab\n","!nvidia-smi\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"g7WbZF-Zf9SK","executionInfo":{"status":"ok","timestamp":1725209641715,"user_tz":-120,"elapsed":835,"user":{"displayName":"Oscar Diez","userId":"15296249123884043247"}},"outputId":"f55dee76-80f4-4c07-db06-a0c7903bc046"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Sun Sep  1 16:54:00 2024       \n","+---------------------------------------------------------------------------------------+\n","| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n","|-----------------------------------------+----------------------+----------------------+\n","| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n","|                                         |                      |               MIG M. |\n","|=========================================+======================+======================|\n","|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n","| N/A   54C    P8              10W /  70W |      0MiB / 15360MiB |      0%      Default |\n","|                                         |                      |                  N/A |\n","+-----------------------------------------+----------------------+----------------------+\n","                                                                                         \n","+---------------------------------------------------------------------------------------+\n","| Processes:                                                                            |\n","|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n","|        ID   ID                                                             Usage      |\n","|=======================================================================================|\n","|  No running processes found                                                           |\n","+---------------------------------------------------------------------------------------+\n"]}]},{"cell_type":"code","source":["# Write the CUDA C code for matrix multiplication to a file\n","cuda_code = \"\"\"\n","#include <stdio.h>\n","#include <cuda_runtime.h>\n","\n","#define N 512  // Define the size of the matrix\n","\n","__global__ void matrixMul(float *A, float *B, float *C, int n) {\n","    int row = blockIdx.y * blockDim.y + threadIdx.y;\n","    int col = blockIdx.x * blockDim.x + threadIdx.x;\n","    float sum = 0.0;\n","\n","    if (row < n && col < n) {\n","        for (int i = 0; i < n; ++i) {\n","            sum += A[row * n + i] * B[i * n + col];\n","        }\n","        C[row * n + col] = sum;\n","    }\n","}\n","\n","int main() {\n","    int size = N * N * sizeof(float);\n","\n","    // Allocate memory on the host\n","    float *h_A = (float *)malloc(size);\n","    float *h_B = (float *)malloc(size);\n","    float *h_C = (float *)malloc(size);\n","\n","    // Initialize matrices A and B with more variation\n","    for (int i = 0; i < N * N; ++i) {\n","        int row = i / N;\n","        int col = i % N;\n","        h_A[i] = (row + 1) + (col % 5);  // Create variation across rows and columns\n","        h_B[i] = (col + 1) * (row % 3 + 1);  // Create variation across rows and columns\n","    }\n","\n","    // Allocate memory on the device\n","    float *d_A, *d_B, *d_C;\n","    cudaMalloc((void **)&d_A, size);\n","    cudaMalloc((void **)&d_B, size);\n","    cudaMalloc((void **)&d_C, size);\n","\n","    // Copy matrices from host to device\n","    cudaMemcpy(d_A, h_A, size, cudaMemcpyHostToDevice);\n","    cudaMemcpy(d_B, h_B, size, cudaMemcpyHostToDevice);\n","\n","    // Define the block size and grid size\n","    dim3 threadsPerBlock(16, 16);\n","    dim3 blocksPerGrid((N + threadsPerBlock.x - 1) / threadsPerBlock.x,\n","                       (N + threadsPerBlock.y - 1) / threadsPerBlock.y);\n","\n","    // Launch the matrix multiplication kernel\n","    matrixMul<<<blocksPerGrid, threadsPerBlock>>>(d_A, d_B, d_C, N);\n","\n","    // Copy the result matrix back to the host\n","    cudaMemcpy(h_C, d_C, size, cudaMemcpyDeviceToHost);\n","\n","    // Print the result matrix\n","    printf(\"Result matrix C (only showing a part of it):\\\\n\");\n","    for (int i = 0; i < 10; ++i) {\n","        for (int j = 0; j < 10; ++j) {\n","            printf(\"%f \", h_C[i * N + j]);\n","        }\n","        printf(\"\\\\n\");\n","    }\n","\n","    // Free memory on device and host\n","    cudaFree(d_A);\n","    cudaFree(d_B);\n","    cudaFree(d_C);\n","    free(h_A);\n","    free(h_B);\n","    free(h_C);\n","\n","    return 0;\n","}\n","\"\"\"\n","\n","with open('matrix_mul.cu', 'w') as f:\n","    f.write(cuda_code)\n"],"metadata":{"id":"VAnfEQKOggER"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Understanding the CUDA Matrix Multiplication Code\n","\n","This CUDA program performs matrix multiplication, a fundamental operation in many scientific and engineering applications, by leveraging the parallel processing power of GPUs.\n","\n","- **Matrix Size Definition**: `#define N 512` sets the matrix dimensions to 512x512, which can be adjusted as needed.\n","\n","- **CUDA Kernel Function (`matrixMul`)**: The kernel function performs the actual multiplication. Each thread computes a single element of the result matrix `C` by iterating over a row of matrix `A` and a column of matrix `B`. The `blockIdx` and `threadIdx` are used to determine the position of the element each thread is responsible for.\n","\n","- **Memory Management**:\n","  - **Host Memory**: Memory for matrices `A`, `B`, and `C` is allocated on the host (CPU) using `malloc`.\n","  - **Device Memory**: Corresponding memory on the GPU is allocated using `cudaMalloc`.\n","  - **Data Transfer**: The matrices `A` and `B` are copied from the host to the GPU before computation, and the result matrix `C` is copied back from the GPU to the host after the kernel execution.\n","\n","- **Grid and Block Configuration**: The grid and block dimensions are set using `dim3`, with a 16x16 block size to distribute the workload among the GPU threads efficiently.\n","\n","- **Kernel Launch**: The `matrixMul` kernel is launched with the specified grid and block dimensions to perform the matrix multiplication on the GPU.\n","\n","- **Result Output**: After computation, a portion of the result matrix `C` is printed to verify the output.\n","\n","- **Memory Cleanup**: Finally, both host and device memory are freed to prevent memory leaks.\n","\n","This example highlights the essential steps in a CUDA program, including memory management, kernel configuration, and parallel computation, providing a foundation for more complex GPU-accelerated applications.\n"],"metadata":{"id":"-HsHEWxbwQax"}},{"cell_type":"markdown","source":["## Running the CUDA Program\n","\n","Next, we'll compile and run the CUDA program to see how GPU-based matrix multiplication works. The result matrix should reflect the combined computation of the two input matrices.\n","\n","We'll use `nvcc`, the CUDA compiler, to compile the code and then execute the compiled binary. If everything is set up correctly, you should see the output of the matrix multiplication displayed below.\n"],"metadata":{"id":"50agN1c2vrYy"}},{"cell_type":"code","source":["# Compile the CUDA program\n","!nvcc -o matrix_mul matrix_mul.cu\n","\n"],"metadata":{"id":"e4kyWq0Vgh9y"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Run the CUDA program\n","!./matrix_mul\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"glr9Uv_cgih5","executionInfo":{"status":"ok","timestamp":1725210582967,"user_tz":-120,"elapsed":481,"user":{"displayName":"Oscar Diez","userId":"15296249123884043247"}},"outputId":"01a236bd-6dc5-4ccd-dd5d-a3ae058fdc0c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Result matrix C (only showing a part of it):\n","3065.000000 6130.000000 9195.000000 12260.000000 15325.000000 18390.000000 21455.000000 24520.000000 27585.000000 30650.000000 \n","4088.000000 8176.000000 12264.000000 16352.000000 20440.000000 24528.000000 28616.000000 32704.000000 36792.000000 40880.000000 \n","5111.000000 10222.000000 15333.000000 20444.000000 25555.000000 30666.000000 35777.000000 40888.000000 45999.000000 51110.000000 \n","6134.000000 12268.000000 18402.000000 24536.000000 30670.000000 36804.000000 42938.000000 49072.000000 55206.000000 61340.000000 \n","7157.000000 14314.000000 21471.000000 28628.000000 35785.000000 42942.000000 50099.000000 57256.000000 64413.000000 71570.000000 \n","8180.000000 16360.000000 24540.000000 32720.000000 40900.000000 49080.000000 57260.000000 65440.000000 73620.000000 81800.000000 \n","9203.000000 18406.000000 27609.000000 36812.000000 46015.000000 55218.000000 64421.000000 73624.000000 82827.000000 92030.000000 \n","10226.000000 20452.000000 30678.000000 40904.000000 51130.000000 61356.000000 71582.000000 81808.000000 92034.000000 102260.000000 \n","11249.000000 22498.000000 33747.000000 44996.000000 56245.000000 67494.000000 78743.000000 89992.000000 101241.000000 112490.000000 \n","12272.000000 24544.000000 36816.000000 49088.000000 61360.000000 73632.000000 85904.000000 98176.000000 110448.000000 122720.000000 \n"]}]},{"cell_type":"code","source":["# Write the CUDA C code for dense and sparse matrix multiplication to a file\n","cuda_code = \"\"\"\n","#include <stdio.h>\n","#include <cuda_runtime.h>\n","\n","#define N 512  // Define the size of the matrix\n","\n","// Kernel for dense matrix multiplication\n","__global__ void denseMatrixMul(float *A, float *B, float *C, int n) {\n","    int row = blockIdx.y * blockDim.y + threadIdx.y;\n","    int col = blockIdx.x * blockDim.x + threadIdx.x;\n","    float sum = 0.0;\n","\n","    if (row < n && col < n) {\n","        for (int i = 0; i < n; ++i) {\n","            sum += A[row * n + i] * B[i * n + col];\n","        }\n","        C[row * n + col] = sum;\n","    }\n","}\n","\n","// Kernel for sparse matrix multiplication (simplified for demo purposes)\n","__global__ void sparseMatrixMul(int *rowPtr, int *colInd, float *values, float *B, float *C, int n, int nnz) {\n","    int row = blockIdx.y * blockDim.y + threadIdx.y;\n","    int col = blockIdx.x * blockDim.x + threadIdx.x;\n","    float sum = 0.0;\n","\n","    if (row < n && col < n) {\n","        for (int idx = rowPtr[row]; idx < rowPtr[row + 1]; ++idx) {\n","            int j = colInd[idx];\n","            sum += values[idx] * B[j * n + col];\n","        }\n","        C[row * n + col] = sum;\n","    }\n","}\n","\n","int main() {\n","    int size = N * N * sizeof(float);\n","\n","    // Allocate memory on the host for dense matrices\n","    float *h_A = (float *)malloc(size);\n","    float *h_B = (float *)malloc(size);\n","    float *h_C_dense = (float *)malloc(size);\n","    float *h_C_sparse = (float *)malloc(size);\n","\n","\n","    // Initialize dense matrices A and B with varying values\n","    for (int i = 0; i < N * N; ++i) {\n","        h_A[i] = ((i % N) + 1) * ((i / N) % 3 + 1);  // Example: values are products of row and column indices with some variation\n","        h_B[i] = ((i / N) + 1) * 0.5f * ((i % N) % 4 + 1);  // Example: values depend on both row and column indices with multiplication factors\n","    }\n","\n","\n","    // Allocate memory on the device for dense matrices\n","    float *d_A, *d_B, *d_C_dense;\n","    cudaMalloc((void **)&d_A, size);\n","    cudaMalloc((void **)&d_B, size);\n","    cudaMalloc((void **)&d_C_dense, size);\n","\n","    // Copy matrices from host to device for dense multiplication\n","    cudaMemcpy(d_A, h_A, size, cudaMemcpyHostToDevice);\n","    cudaMemcpy(d_B, h_B, size, cudaMemcpyHostToDevice);\n","\n","    // Define the block size and grid size for dense multiplication\n","    dim3 threadsPerBlock(16, 16);\n","    dim3 blocksPerGrid((N + threadsPerBlock.x - 1) / threadsPerBlock.x,\n","                       (N + threadsPerBlock.y - 1) / threadsPerBlock.y);\n","\n","    // Launch the dense matrix multiplication kernel\n","    denseMatrixMul<<<blocksPerGrid, threadsPerBlock>>>(d_A, d_B, d_C_dense, N);\n","\n","    // Copy the result matrix back to the host for dense multiplication\n","    cudaMemcpy(h_C_dense, d_C_dense, size, cudaMemcpyDeviceToHost);\n","\n","    // Print results for dense matrix multiplication\n","    printf(\"Result matrix C (Dense - showing a part of it):\\\\n\");\n","    for (int i = 0; i < 10; ++i) {\n","        for (int j = 0; j < 10; ++j) {\n","            printf(\"%f \", h_C_dense[i * N + j]);\n","        }\n","        printf(\"\\\\n\");\n","    }\n","\n","    // Example of sparse matrix multiplication\n","    // Note: Sparse matrix in CSR format is represented by rowPtr, colInd, and values arrays\n","    int nnz = 3 * N;  // Example: 3 non-zero entries per row\n","    int *h_rowPtr = (int *)malloc((N + 1) * sizeof(int));\n","    int *h_colInd = (int *)malloc(nnz * sizeof(int));\n","    float *h_values = (float *)malloc(nnz * sizeof(float));\n","\n","\n","    // Initialize sparse matrix A in CSR format\n","    for (int i = 0; i < N; ++i) {\n","        h_rowPtr[i] = i * 3;  // 3 non-zeros per row\n","        for (int j = 0; j < 3; ++j) {\n","            h_colInd[i * 3 + j] = (i + j) % N;  // Example column indices\n","            h_values[i * 3 + j] = 1.0f;  // Non-zero values\n","        }\n","    }\n","    h_rowPtr[N] = nnz;  // Last entry of rowPtr\n","\n","    // Allocate memory on the device for sparse matrix multiplication\n","    int *d_rowPtr, *d_colInd;\n","    float *d_values, *d_C_sparse;\n","    cudaMalloc((void **)&d_rowPtr, (N + 1) * sizeof(int));\n","    cudaMalloc((void **)&d_colInd, nnz * sizeof(int));\n","    cudaMalloc((void **)&d_values, nnz * sizeof(float));\n","    cudaMalloc((void **)&d_C_sparse, size);\n","\n","    // Copy sparse matrix data from host to device\n","    cudaMemcpy(d_rowPtr, h_rowPtr, (N + 1) * sizeof(int), cudaMemcpyHostToDevice);\n","    cudaMemcpy(d_colInd, h_colInd, nnz * sizeof(int), cudaMemcpyHostToDevice);\n","    cudaMemcpy(d_values, h_values, nnz * sizeof(float), cudaMemcpyHostToDevice);\n","    cudaMemcpy(d_B, h_B, size, cudaMemcpyHostToDevice);  // Reuse B from dense multiplication\n","\n","    // Launch the sparse matrix multiplication kernel\n","    sparseMatrixMul<<<blocksPerGrid, threadsPerBlock>>>(d_rowPtr, d_colInd, d_values, d_B, d_C_sparse, N, nnz);\n","\n","    // Copy the result matrix back to the host for sparse multiplication\n","    cudaMemcpy(h_C_sparse, d_C_sparse, size, cudaMemcpyDeviceToHost);\n","\n","    // Print results for sparse matrix multiplication\n","    printf(\"\\\\nResult matrix C (Sparse - showing a part of it):\\\\n\");\n","    for (int i = 0; i < 10; ++i) {\n","        for (int j = 0; j < 10; ++j) {\n","            printf(\"%f \", h_C_sparse[i * N + j]);\n","        }\n","        printf(\"\\\\n\");\n","    }\n","\n","    // Free memory on device and host\n","    cudaFree(d_A);\n","    cudaFree(d_B);\n","    cudaFree(d_C_dense);\n","    cudaFree(d_rowPtr);\n","    cudaFree(d_colInd);\n","    cudaFree(d_values);\n","    cudaFree(d_C_sparse);\n","    free(h_A);\n","    free(h_B);\n","    free(h_C_dense);\n","    free(h_C_sparse);\n","    free(h_rowPtr);\n","    free(h_colInd);\n","    free(h_values);\n","\n","    return 0;\n","}\n","\"\"\"\n","\n","with open('matrix_mul.cu', 'w') as f:\n","    f.write(cuda_code)\n"],"metadata":{"id":"BAB8gBMShm4E"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Understanding the CUDA Code for Dense and Sparse Matrix Multiplication\n","\n","This CUDA program demonstrates two different approaches to matrix multiplication: dense and sparse. Matrix multiplication is a core operation in many high-performance computing applications, and understanding both dense and sparse implementations is crucial for optimizing performance depending on the data characteristics.\n","\n","### Dense Matrix Multiplication\n","- **Kernel Function (`denseMatrixMul`)**: This kernel computes the product of two dense matrices `A` and `B`, storing the result in matrix `C`. Each thread is responsible for calculating a single element in the result matrix `C` by iterating over a row in `A` and a column in `B`.\n","- **Host and Device Memory Management**:\n","  - **Host Memory**: Allocated for matrices `A`, `B`, and `C_dense` using `malloc`.\n","  - **Device Memory**: Corresponding memory is allocated on the GPU using `cudaMalloc`.\n","  - **Data Transfer**: Matrices `A` and `B` are copied from host to device memory before the kernel is executed, and the resulting matrix `C_dense` is copied back to the host after the kernel execution.\n","- **Kernel Launch Configuration**: The matrix multiplication kernel is launched with a grid and block configuration determined by the size of the matrix and the number of threads per block, maximizing GPU resource utilization.\n","\n","### Sparse Matrix Multiplication\n","- **Sparse Matrix Representation**: Sparse matrices store only non-zero elements to save memory and computation time. Here, the sparse matrix `A` is represented in Compressed Sparse Row (CSR) format using three arrays: `rowPtr`, `colInd`, and `values`.\n","  - **`rowPtr`**: Indicates the start and end of each row in the `colInd` and `values` arrays.\n","  - **`colInd`**: Stores the column indices of the non-zero elements.\n","  - **`values`**: Stores the actual non-zero values of the matrix.\n","- **Kernel Function (`sparseMatrixMul`)**: This kernel performs matrix multiplication using the sparse matrix `A` and dense matrix `B`, storing the result in matrix `C_sparse`. Each thread computes a single element in `C_sparse` by accessing only the non-zero elements in `A`.\n","- **Host and Device Memory Management**:\n","  - **Host Memory**: Additional memory is allocated for the sparse matrix representation (`rowPtr`, `colInd`, and `values`).\n","  - **Device Memory**: Memory for the sparse matrix components and the result matrix `C_sparse` is allocated on the GPU.\n","  - **Data Transfer**: Sparse matrix data is copied from host to device before kernel execution, and the resulting matrix `C_sparse` is copied back to the host afterward.\n","\n","### Result Verification and Output\n","- After executing both the dense and sparse matrix multiplication kernels, the program prints a portion of the resulting matrices `C_dense` and `C_sparse`. This output allows for verification of the correctness of the matrix multiplication operations.\n","\n","### Memory Cleanup\n","- The program ensures proper cleanup by freeing both host and device memory after the computation, preventing memory leaks and ensuring efficient use of resources.\n","\n","This code provides a practical example of how to implement and compare dense and sparse matrix multiplication on a GPU using CUDA, demonstrating the advantages of using sparse matrices when dealing with data that contains many zeroes.\n"],"metadata":{"id":"kGE8j3DpwwKA"}},{"cell_type":"code","source":["# Compile the CUDA program\n","!nvcc -lcusparse -o matrix_mul matrix_mul.cu\n"],"metadata":{"id":"F2kshwuChp86"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Run the CUDA program\n","!./matrix_mul\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UseLLvt1hrMS","executionInfo":{"status":"ok","timestamp":1725210414290,"user_tz":-120,"elapsed":413,"user":{"displayName":"Oscar Diez","userId":"15296249123884043247"}},"outputId":"d919c4d1-7f89-45c2-f809-dcbb33068682"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Result matrix C (Dense - showing a part of it):\n","22435164.000000 44870328.000000 67305608.000000 89740656.000000 22435164.000000 44870328.000000 67305608.000000 89740656.000000 22435164.000000 44870328.000000 \n","44870328.000000 89740656.000000 134611216.000000 179481312.000000 44870328.000000 89740656.000000 134611216.000000 179481312.000000 44870328.000000 89740656.000000 \n","67305608.000000 134611216.000000 201916704.000000 269222432.000000 67305608.000000 134611216.000000 201916704.000000 269222432.000000 67305608.000000 134611216.000000 \n","22435164.000000 44870328.000000 67305608.000000 89740656.000000 22435164.000000 44870328.000000 67305608.000000 89740656.000000 22435164.000000 44870328.000000 \n","44870328.000000 89740656.000000 134611216.000000 179481312.000000 44870328.000000 89740656.000000 134611216.000000 179481312.000000 44870328.000000 89740656.000000 \n","67305608.000000 134611216.000000 201916704.000000 269222432.000000 67305608.000000 134611216.000000 201916704.000000 269222432.000000 67305608.000000 134611216.000000 \n","22435164.000000 44870328.000000 67305608.000000 89740656.000000 22435164.000000 44870328.000000 67305608.000000 89740656.000000 22435164.000000 44870328.000000 \n","44870328.000000 89740656.000000 134611216.000000 179481312.000000 44870328.000000 89740656.000000 134611216.000000 179481312.000000 44870328.000000 89740656.000000 \n","67305608.000000 134611216.000000 201916704.000000 269222432.000000 67305608.000000 134611216.000000 201916704.000000 269222432.000000 67305608.000000 134611216.000000 \n","22435164.000000 44870328.000000 67305608.000000 89740656.000000 22435164.000000 44870328.000000 67305608.000000 89740656.000000 22435164.000000 44870328.000000 \n","\n","Result matrix C (Sparse - showing a part of it):\n","3.000000 6.000000 9.000000 12.000000 3.000000 6.000000 9.000000 12.000000 3.000000 6.000000 \n","4.500000 9.000000 13.500000 18.000000 4.500000 9.000000 13.500000 18.000000 4.500000 9.000000 \n","6.000000 12.000000 18.000000 24.000000 6.000000 12.000000 18.000000 24.000000 6.000000 12.000000 \n","7.500000 15.000000 22.500000 30.000000 7.500000 15.000000 22.500000 30.000000 7.500000 15.000000 \n","9.000000 18.000000 27.000000 36.000000 9.000000 18.000000 27.000000 36.000000 9.000000 18.000000 \n","10.500000 21.000000 31.500000 42.000000 10.500000 21.000000 31.500000 42.000000 10.500000 21.000000 \n","12.000000 24.000000 36.000000 48.000000 12.000000 24.000000 36.000000 48.000000 12.000000 24.000000 \n","13.500000 27.000000 40.500000 54.000000 13.500000 27.000000 40.500000 54.000000 13.500000 27.000000 \n","15.000000 30.000000 45.000000 60.000000 15.000000 30.000000 45.000000 60.000000 15.000000 30.000000 \n","16.500000 33.000000 49.500000 66.000000 16.500000 33.000000 49.500000 66.000000 16.500000 33.000000 \n"]}]},{"cell_type":"markdown","source":["# OpenACC"],"metadata":{"id":"A4NBFxDIkO_p"}},{"cell_type":"markdown","source":["## Introduction to OpenACC\n","\n","While CUDA is a powerful and flexible tool for GPU programming, it requires detailed management of the GPU's memory and parallelization. OpenACC is a higher-level programming model designed to simplify the process of parallelizing code. With OpenACC, you can accelerate your existing C, C++, and Fortran applications without requiring in-depth knowledge of GPU architecture.\n","\n","### Key Concepts in OpenACC\n","\n","- **Directives**: OpenACC uses compiler directives (pragmas) to specify which parts of the code should run on the GPU. This allows for incremental parallelization of existing code.\n","- **Parallel Region**: A block of code that is executed by multiple threads in parallel on the GPU.\n","- **Data Region**: Specifies the movement of data between the CPU and GPU memory.\n","\n","Let's take a look at a similar matrix multiplication example using OpenACC.\n"],"metadata":{"id":"3O5QPvXsvz2a"}},{"cell_type":"code","source":["# Install wget and the necessary dependencies\n","!apt-get install -y wget build-essential\n","\n","# Download the NVIDIA HPC SDK\n","!wget https://developer.download.nvidia.com/hpc-sdk/23.1/nvhpc_2023_231_Linux_x86_64_cuda_12.0.tar.gz -O nvhpc.tar.gz\n","\n","# Extract the downloaded tarball\n","!tar -xzf nvhpc.tar.gz\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"t4i4HxRVkSCP","executionInfo":{"status":"ok","timestamp":1725211455092,"user_tz":-120,"elapsed":222344,"user":{"displayName":"Oscar Diez","userId":"15296249123884043247"}},"outputId":"bec6d848-f0c4-4379-b20d-21d570f0c63d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Reading package lists... Done\n","Building dependency tree... Done\n","Reading state information... Done\n","build-essential is already the newest version (12.9ubuntu3).\n","wget is already the newest version (1.21.2-2ubuntu1.1).\n","0 upgraded, 0 newly installed, 0 to remove and 49 not upgraded.\n","--2024-09-01 17:20:34--  https://developer.download.nvidia.com/hpc-sdk/23.1/nvhpc_2023_231_Linux_x86_64_cuda_12.0.tar.gz\n","Resolving developer.download.nvidia.com (developer.download.nvidia.com)... 152.199.39.144\n","Connecting to developer.download.nvidia.com (developer.download.nvidia.com)|152.199.39.144|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 5084055249 (4.7G) [application/x-gzip]\n","Saving to: ‘nvhpc.tar.gz’\n","\n","nvhpc.tar.gz        100%[===================>]   4.73G  64.0MB/s    in 76s     \n","\n","2024-09-01 17:21:50 (64.1 MB/s) - ‘nvhpc.tar.gz’ saved [5084055249/5084055249]\n","\n"]}]},{"cell_type":"code","source":["# Navigate to the extracted folder and run the install script non-interactively\n","!cd nvhpc_2023_231_Linux_x86_64_cuda_12.0 && yes \"\" | ./install --installpath /usr/local/nvhpc --accept --silent\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RMv6iELpmnsl","executionInfo":{"status":"ok","timestamp":1725212285402,"user_tz":-120,"elapsed":88911,"user":{"displayName":"Oscar Diez","userId":"15296249123884043247"}},"outputId":"10e410d5-e4ce-4a57-b36c-2ff55f91f6d8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Welcome to the NVIDIA HPC SDK Linux installer!\n","\n","You are installing NVIDIA HPC SDK 2023 version 23.1 for Linux_x86_64.\n","Please note that all Trademarks and Marks are the properties\n","of their respective owners.\n","\n","Press enter to continue...\n","\n","A network installation will save disk space by having only one copy of the\n","compilers and most of the libraries for all compilers on the network, and\n","the main installation needs to be done once for all systems on the network.\n","\n","1  Single system install\n","2  Network install\n","\n","Please choose install option: \n","\n","Please specify the directory path under which the software will be installed.\n","The default directory is /opt/nvidia/hpc_sdk, but you may install anywhere you wish,\n","assuming you have permission to do so.\n","\n","Installation directory? [/opt/nvidia/hpc_sdk] \n","\n","Note: directory /opt/nvidia/hpc_sdk was created.\n","\n","Installing NVIDIA HPC SDK version 23.1 into /opt/nvidia/hpc_sdk\n","Making symbolic links in /opt/nvidia/hpc_sdk/Linux_x86_64/2023\n","\n","generating environment modules for NV HPC SDK 23.1 ... done.\n","Installation complete.\n","HPC SDK successfully installed into /opt/nvidia/hpc_sdk\n","\n","If you use the Environment Modules package, that is, the module load\n","command, the NVIDIA HPC SDK includes a script to set up the\n","appropriate module files.\n","\n","% module load /opt/nvidia/hpc_sdk/modulefiles/nvhpc/23.1\n","% module load nvhpc/23.1\n","\n","Alternatively, the shell environment may be initialized to use the HPC SDK.\n","\n","In csh, use these commands:\n","\n","% setenv MANPATH \"$MANPATH\":/opt/nvidia/hpc_sdk/Linux_x86_64/23.1/compilers/man\n","% set path = (/opt/nvidia/hpc_sdk/Linux_x86_64/23.1/compilers/bin $path)\n","\n","In bash, sh, or ksh, use these commands:\n","\n","$ MANPATH=$MANPATH:/opt/nvidia/hpc_sdk/Linux_x86_64/23.1/compilers/man; export MANPATH\n","$ PATH=/opt/nvidia/hpc_sdk/Linux_x86_64/23.1/compilers/bin:$PATH; export PATH\n","\n","Once the 64-bit compilers are available, you can make the OpenMPI\n","commands and man pages accessible using these commands.\n","\n","% set path = (/opt/nvidia/hpc_sdk/Linux_x86_64/23.1/comm_libs/mpi/bin $path)\n","% setenv MANPATH \"$MANPATH\":/opt/nvidia/hpc_sdk/Linux_x86_64/23.1/comm_libs/mpi/man\n","\n","And the equivalent in bash, sh, and ksh:\n","\n","$ export PATH=/opt/nvidia/hpc_sdk/Linux_x86_64/23.1/comm_libs/mpi/bin:$PATH\n","$ export MANPATH=$MANPATH:/opt/nvidia/hpc_sdk/Linux_x86_64/23.1/comm_libs/mpi/man\n","\n","Please check https://developer.nvidia.com for documentation,\n","use of NVIDIA HPC SDK software, and other questions.\n","\n"]}]},{"cell_type":"code","source":["import os\n","# Set up environment variables for the NVIDIA HPC SDK installed in /opt/nvidia/hpc_sdk\n","os.environ['PATH'] = '/opt/nvidia/hpc_sdk/Linux_x86_64/23.1/compilers/bin:' + os.environ['PATH']\n","os.environ['LD_LIBRARY_PATH'] = '/opt/nvidia/hpc_sdk/Linux_x86_64/23.1/compilers/lib:' + os.environ['LD_LIBRARY_PATH']\n"],"metadata":{"id":"v_W_Hy0Qr9HN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Check if nvc is in the PATH\n","!which nvc\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nIYBqrR8rq-d","executionInfo":{"status":"ok","timestamp":1725212925286,"user_tz":-120,"elapsed":841,"user":{"displayName":"Oscar Diez","userId":"15296249123884043247"}},"outputId":"b3a14e39-be1b-4818-967b-ae4ce246394e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/opt/nvidia/hpc_sdk/Linux_x86_64/23.1/compilers/bin/nvc\n"]}]},{"cell_type":"code","source":["openacc_code = \"\"\"\n","#include <stdio.h>\n","#include <stdlib.h>\n","\n","#define N 512  // Define the size of the matrix\n","\n","int main() {\n","    int size = N * N * sizeof(float);\n","\n","    // Allocate memory on the host\n","    float *A = (float *)malloc(size);\n","    float *B = (float *)malloc(size);\n","    float *C = (float *)malloc(size);\n","\n","    // Initialize matrices A and B with varying values\n","    for (int i = 0; i < N * N; i++) {\n","        int row = i / N;\n","        int col = i % N;\n","        A[i] = (float)((row + 1) * (col + 2)) * 0.5f;  // Initialize A with values based on row and column\n","        B[i] = (float)((col + 1) * (row + 2)) * 0.3f;  // Initialize B with values based on row and column\n","    }\n","\n","    // Perform matrix multiplication using OpenACC\n","    #pragma acc data copyin(A[0:N*N], B[0:N*N]), copyout(C[0:N*N])\n","    {\n","        #pragma acc parallel loop collapse(2)\n","        for (int i = 0; i < N; i++) {\n","            for (int j = 0; j < N; j++) {\n","                float sum = 0.0f;\n","                for (int k = 0; k < N; k++) {\n","                    sum += A[i * N + k] * B[k * N + j];\n","                }\n","                C[i * N + j] = sum;\n","            }\n","        }\n","    }\n","\n","    // Print a portion of the result matrix\n","    printf(\"Result matrix C (only showing a part of it):\\\\n\");\n","    for (int i = 0; i < 10; i++) {\n","        for (int j = 0; j < 10; j++) {\n","            printf(\"%f \", C[i * N + j]);\n","        }\n","        printf(\"\\\\n\");\n","    }\n","\n","    // Free memory\n","    free(A);\n","    free(B);\n","    free(C);\n","\n","    return 0;\n","}\n","\"\"\"\n","\n","# Save the OpenACC code to a file\n","with open('matrix_mul_openacc.c', 'w') as f:\n","    f.write(openacc_code)\n"],"metadata":{"id":"JGgOfJcIkXqG"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Understanding the OpenACC Code for Matrix Multiplication\n","\n","This OpenACC program demonstrates matrix multiplication, a fundamental operation in many scientific computing tasks, using GPU acceleration. OpenACC is a user-friendly directive-based programming model that allows developers to parallelize code easily and target accelerators like GPUs without deep knowledge of GPU architecture.\n","\n","### Matrix Initialization\n","- **Matrix Size and Memory Allocation**:\n","  - The matrix size `N` is defined as 512, resulting in matrices `A`, `B`, and `C` of size 512x512.\n","  - Memory for these matrices is allocated on the host using `malloc`, with each matrix occupying `N*N*sizeof(float)` bytes.\n","  \n","- **Initializing Matrices**:\n","  - Matrices `A` and `B` are initialized with varying values based on their row and column indices. This variation ensures that each element in the matrices has a unique value, allowing for meaningful computation and results.\n","  - Matrix `A` is filled with values calculated as `((row + 1) * (col + 2)) * 0.5f`.\n","  - Matrix `B` is initialized with values calculated as `((col + 1) * (row + 2)) * 0.3f`.\n","\n","### Parallel Matrix Multiplication with OpenACC\n","- **OpenACC Directives**:\n","  - The `#pragma acc data` directive is used to manage data transfer between the host and the device (GPU). It ensures that matrices `A` and `B` are copied to the device before the computation, and matrix `C` is copied back to the host after the computation.\n","  - The `#pragma acc parallel loop collapse(2)` directive specifies that the following nested loops should be parallelized, allowing multiple threads on the GPU to perform the matrix multiplication concurrently. The `collapse(2)` clause indicates that both loops should be parallelized together, enabling efficient use of the GPU's parallel architecture.\n","\n","- **Matrix Multiplication**:\n","  - The nested loops iterate over the rows of `A` and columns of `B` to compute each element of the result matrix `C`. Each element `C[i * N + j]` is calculated as the dot product of the `i-th` row of `A` and the `j-th` column of `B`.\n","  - The inner loop accumulates the product of corresponding elements from `A` and `B`, storing the sum in `C`.\n","\n","### Result Display and Memory Cleanup\n","- **Output**:\n","  - After computation, the program prints a portion of the result matrix `C` (the top-left 10x10 submatrix). This partial display allows for quick verification of the computation's correctness.\n","  \n","- **Memory Management**:\n","  - The program concludes by freeing the allocated memory for matrices `A`, `B`, and `C` on the host, ensuring efficient use of resources and preventing memory leaks.\n","\n","This code provides a practical example of how to use OpenACC for parallelizing a common computational task (matrix multiplication) and demonstrates how OpenACC simplifies the process of leveraging GPU acceleration.\n"],"metadata":{"id":"uOgHQlm6w2Uf"}},{"cell_type":"markdown","source":["## Running the OpenACC Program\n","\n","Now that we've written our OpenACC code for matrix multiplication, let's compile and run it. The OpenACC program should produce a result matrix similar to the CUDA version but with potentially simpler code.\n","\n","OpenACC abstracts much of the complexity of GPU programming, making it easier to parallelize existing C or Fortran code. Let's see how it performs.\n"],"metadata":{"id":"dVQY_rl8v8Sy"}},{"cell_type":"code","source":["# Compile the OpenACC code using nvc (NVIDIA C Compiler) from the HPC SDK\n","!nvc -acc -o matrix_mul_openacc matrix_mul_openacc.c -Minfo=accel\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tsftQsGtkZmm","executionInfo":{"status":"ok","timestamp":1725213139595,"user_tz":-120,"elapsed":396,"user":{"displayName":"Oscar Diez","userId":"15296249123884043247"}},"outputId":"c7b37c93-ae19-4d9a-a6b4-ffcff18c1009"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["main:\n","     25, Generating copyin(A[:262144]) [if not already present]\n","         Generating copyout(C[:262144]) [if not already present]\n","         Generating copyin(B[:262144]) [if not already present]\n","         Generating NVIDIA GPU code\n","         27, #pragma acc loop gang collapse(2) /* blockIdx.x */\n","         28,   /* blockIdx.x collapsed */\n","         30, #pragma acc loop vector(128) /* threadIdx.x */\n","             Generating implicit reduction(+:sum)\n","     30, Loop is parallelizable\n"]}]},{"cell_type":"code","source":["# Run the OpenACC program\n","!./matrix_mul_openacc\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iMsJzBSckbdG","executionInfo":{"status":"ok","timestamp":1725213148269,"user_tz":-120,"elapsed":933,"user":{"displayName":"Oscar Diez","userId":"15296249123884043247"}},"outputId":"dd377c8b-c73d-4985-d58a-4947aaee09d9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Result matrix C (only showing a part of it):\n","6770035.000000 13540070.000000 20310106.000000 27080140.000000 33850176.000000 40620212.000000 47390248.000000 54160280.000000 60930320.000000 67700352.000000 \n","13540070.000000 27080140.000000 40620212.000000 54160280.000000 67700352.000000 81240424.000000 94780496.000000 108320560.000000 121860640.000000 135400704.000000 \n","20310108.000000 40620216.000000 60930320.000000 81240432.000000 101550528.000000 121860640.000000 142170736.000000 162480864.000000 182790944.000000 203101056.000000 \n","27080140.000000 54160280.000000 81240424.000000 108320560.000000 135400704.000000 162480848.000000 189560992.000000 216641120.000000 243721280.000000 270801408.000000 \n","33850176.000000 67700352.000000 101550528.000000 135400704.000000 169250880.000000 203101056.000000 236951232.000000 270801408.000000 304651584.000000 338501760.000000 \n","40620216.000000 81240432.000000 121860640.000000 162480864.000000 203101056.000000 243721280.000000 284341472.000000 324961728.000000 365581888.000000 406202112.000000 \n","47390248.000000 94780496.000000 142170752.000000 189560992.000000 236951232.000000 284341504.000000 331731712.000000 379121984.000000 426512224.000000 473902464.000000 \n","54160280.000000 108320560.000000 162480848.000000 216641120.000000 270801408.000000 324961696.000000 379121984.000000 433282240.000000 487442560.000000 541602816.000000 \n","60930320.000000 121860640.000000 182790944.000000 243721280.000000 304651584.000000 365581888.000000 426512256.000000 487442560.000000 548372864.000000 609303168.000000 \n","67700352.000000 135400704.000000 203101056.000000 270801408.000000 338501760.000000 406202112.000000 473902464.000000 541602816.000000 609303168.000000 677003520.000000 \n"]}]},{"cell_type":"markdown","source":["## Comparing CUDA and OpenACC\n","\n","Both CUDA and OpenACC are powerful tools for leveraging the computational power of GPUs, but they serve different purposes and target different audiences:\n","\n","- **CUDA**: Offers more control over the hardware and is ideal for developers who need fine-grained optimization and are familiar with GPU architecture. It requires manual management of memory and parallelization, but this can lead to highly optimized code.\n","\n","- **OpenACC**: Provides a higher-level, more abstracted approach to GPU programming. It's easier to use for those who want to accelerate their applications without diving deeply into the specifics of GPU hardware. OpenACC is often used to incrementally parallelize existing applications.\n","\n","### Key Takeaways\n","\n","- **Flexibility vs. Ease of Use**: CUDA is more flexible but requires more effort, while OpenACC is easier to use but might not offer the same level of optimization.\n","- **Learning Curve**: CUDA has a steeper learning curve compared to OpenACC.\n","- **Performance**: Depending on the application and how well the code is optimized, CUDA might offer better performance, but OpenACC can still deliver significant speedups with much less effort.\n","\n","### Conclusion\n","\n","In this session, we explored the basics of GPU computing, focusing on two popular approaches: CUDA and OpenACC. We've implemented matrix multiplication in both frameworks and compared their usage. Understanding both CUDA and OpenACC allows you to choose the best tool for your specific needs, whether that’s maximum performance or ease of development.\n","\n","Continue experimenting with these examples and explore how you can leverage GPU computing for your projects!\n"],"metadata":{"id":"gz6LLkuxv-5K"}}]}